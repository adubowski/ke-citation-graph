{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Database wrapper from: https://towardsdatascience.com/create-a-graph-database-in-neo4j-using-python-4172d40f89c4\n",
    "\n",
    "\n",
    "class Neo4jConnection:\n",
    "\n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "\n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "\n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try:\n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session()\n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally:\n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n",
    "port = 11005 # Check if is the case for your server!\n",
    "\n",
    "conn = Neo4jConnection(uri=\"bolt://localhost:\"+str(port),\n",
    "                       user=\"driver\",\n",
    "                       pwd=\"driver\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def insert_data(query, rows, batch_size = 10000):\n",
    "    # Function to handle the updating the Neo4j database in batch mode.\n",
    "\n",
    "    total = 0\n",
    "    batch = 0\n",
    "    start = time.time()\n",
    "    result = None\n",
    "\n",
    "    for batch in tqdm(range(len(rows) // batch_size + 1)):\n",
    "        batch_start = time.time()\n",
    "        res = conn.query(query,\n",
    "                         parameters = {'rows': rows[batch*batch_size:(batch+1)*batch_size].to_dict('records')})\n",
    "        total += res[0]['total']\n",
    "        result = {\"batch_size\": batch_size,\n",
    "                  \"batches_done\": batch,\n",
    "                  \"batch_time\": time.time() - batch_start,\n",
    "                  \"total_time\": time.time()-start}\n",
    "        # print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_papers(rows, batch_size=5000):\n",
    "   # Adds paper nodes and relationships (:Author)-[:AUTHORED]-(:Paper), (:Paper)-[:REFERENCES]-(:Paper)\n",
    "   query = '''\n",
    "    // Create papers\n",
    "    UNWIND $rows as paper\n",
    "    MERGE (p:Paper {paperid: paper.id})\n",
    "    ON CREATE SET\n",
    "    p.title = paper.title,\n",
    "    p.year = paper.year,\n",
    "    p.n_citation = paper.n_citation,\n",
    "    p.doi = paper.doi\n",
    "\n",
    "    // Match authors\n",
    "    WITH paper, p\n",
    "    UNWIND  paper.authors AS author\n",
    "    MERGE (a:Author {authorid: author.id})\n",
    "    ON CREATE SET a.name = author.name\n",
    "    MERGE (a)-[:AUTHORED]->(p)\n",
    "\n",
    "    // Match references\n",
    "    WITH paper, p\n",
    "    UNWIND  paper.references AS refid\n",
    "    MATCH (r:Paper {paperid:refid})\n",
    "    MERGE (p)-[:REFERENCES]->(r)\n",
    "    RETURN count(p:Paper) as total\n",
    "   '''\n",
    "\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Couldn't connect to localhost:11005 (resolved to ('[::1]:11005', '127.0.0.1:11005')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 11005, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 11005)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Query failed: Couldn't connect to localhost:11005 (resolved to ('[::1]:11005', '127.0.0.1:11005')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 11005, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 11005)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n"
     ]
    }
   ],
   "source": [
    "conn.query('CREATE INDEX paper_id_index IF NOT EXISTS FOR (p:Paper) ON (p.paperid);')\n",
    "conn.query('CREATE INDEX author_id_index IF NOT EXISTS FOR (a:Author) ON (a.authorid);')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]\n",
      "  0%|          | 0/101 [00:04<?, ?it/s]\u001B[A\n",
      "  0%|          | 0/41 [00:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Couldn't connect to localhost:11005 (resolved to ('[::1]:11005', '127.0.0.1:11005')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 11005, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 11005)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = \"data/dblp_papers_v11.txt\"\n",
    "n_papers = 4107340 # Number of papers in the dataset\n",
    "subset = [\"id\", \"title\", \"year\", \"n_citation\", \"doi\", \"authors\", \"references\"]\n",
    "\n",
    "# TODO: Add tqdm max of the number of papers\n",
    "with open(file, 'r') as f:\n",
    "    for episode in tqdm(range(n_papers // 100000)):\n",
    "        try:\n",
    "            lines = 100000\n",
    "            rows  = []\n",
    "            for line in f:\n",
    "                rows.append(json.loads(line))\n",
    "                lines -= 1\n",
    "                if lines == 0: break\n",
    "            df = pd.DataFrame(rows)\n",
    "            add_papers(df[subset], 1000)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def process_stackexchange(board: str) -> list[pd.DataFrame]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        board (str): Stackexchange board to load. Expected file structure is\n",
    "            ./data/`board`/*.xml\n",
    "\n",
    "    Returns:\n",
    "        list[pd.DataFrame]: List of pandas dataframes with Comments and\n",
    "            PostHistory data with extracted DOIs and markdown links.\n",
    "    \"\"\"\n",
    "    # Regex patterns\n",
    "    DOI_PATTERN = \"10\\.\\d{4,9}/[-._;\\(\\)/:A-Z0-9]+[/A-Z0-9]\"\n",
    "    MD_PATTERN = \"\\[([\\w\\s\\d]+)\\](https?:\\/\\/[\\w\\d./?=#]+)\"\n",
    "\n",
    "    def process_set(set: str) -> pd.DataFrame:\n",
    "        \"\"\"Processes single file in board data\n",
    "\n",
    "        Args:\n",
    "            set (str): One of \"Comments\" or \"PostHistory\"\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Original data with extracted DOIs and Markdown links\n",
    "        \"\"\"\n",
    "        # Load xml file\n",
    "        path = f\"data/{board}/{set}.xml\"\n",
    "        with open(path, encoding=\"utf8\") as file:\n",
    "            df = pd.read_xml(file.read())\n",
    "\n",
    "        # Extract all DOIs using pattern defined before to list per row\n",
    "        df[\"DOIs\"] = df[\"Text\"].apply(lambda text: str(re.findall(DOI_PATTERN, str(text))))\n",
    "        # df = df.loc[df[\"DOIs\"].str.len() > 0]\n",
    "        df[\"board\"] = board\n",
    "        return df\n",
    "\n",
    "    return process_set(\"Comments\"), process_set(\"PostHistory\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def add_boards(rows, batch_size=5000):\n",
    "    # Adds board nodes\n",
    "    query = '''\n",
    "    UNWIND $rows as board\n",
    "    MERGE (b:Board {boardname: board.name})\n",
    "    RETURN count(b:Board) as total\n",
    "    '''\n",
    "    return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def add_posts(rows, batch_size=5000):\n",
    "   # Adds post nodes\n",
    "   query = '''\n",
    "    // Create posts\n",
    "    UNWIND $rows as post\n",
    "    MERGE (p:Post {postid: post.PostId})\n",
    "    ON CREATE SET\n",
    "    p.text = post.Text\n",
    "\n",
    "    WITH post, p\n",
    "    UNWIND post.DOIs AS doi\n",
    "    MATCH (r:Paper {doi:doi})\n",
    "    MERGE (p)-[:REFERENCES]->(r)\n",
    "    RETURN count(p:Post) as total\n",
    "\n",
    "    WITH post, p\n",
    "    MATCH (b:Board {boardname:p.board})\n",
    "    MERGE (p)-[:FROM_BOARD]->(b)\n",
    "    RETURN count(p:Post) as total\n",
    "   '''\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_comments(rows, batch_size=500):\n",
    "   # Adds comment nodes\n",
    "   query = '''\n",
    "    // Create comments\n",
    "    UNWIND $rows as comment\n",
    "    MERGE (c:Comment {commentid: comment.Id})\n",
    "    ON CREATE SET\n",
    "    c.text = comment.Text\n",
    "\n",
    "    // Match posts\n",
    "    WITH comment, c\n",
    "    MATCH (p:Post {postid: comment.PostId})\n",
    "    MERGE (c)-[:RESPONDS_TO]->(p)\n",
    "\n",
    "    // Match references\n",
    "    WITH comment, c\n",
    "    UNWIND comment.DOIs AS doi\n",
    "    MATCH (r:Paper {doi:doi})\n",
    "    MERGE (c)-[:REFERENCES]->(r)\n",
    "    RETURN count(c:Comment) as total\n",
    "   '''\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def add_post_links(rows, batch_size=5000):\n",
    "   # Adds post nodes\n",
    "   query = '''\n",
    "    // Create posts\n",
    "    UNWIND $rows as post_link\n",
    "    MATCH (p:Post {postid:post_link.postid})\n",
    "    MERGE (p)-[:REFERENCES]->(r)\n",
    "    RETURN count(p:Post) as total\n",
    "   '''\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Couldn't connect to localhost:11005 (resolved to ('[::1]:11005', '127.0.0.1:11005')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 11005, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 11005)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m se_boards \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mai\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcstheory\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatascience\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoftwarerecs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m----> 2\u001B[0m \u001B[43madd_boards\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mse_boards\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36madd_boards\u001B[1;34m(rows, batch_size)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd_boards\u001B[39m(rows, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# Adds board nodes\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'''\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124m    UNWIND $rows as board\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124m    MERGE (b:Board \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mboardname: board.name})\u001B[39m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124m    RETURN count(b:Board) as total\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minsert_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36minsert_data\u001B[1;34m(query, rows, batch_size)\u001B[0m\n\u001B[0;32m     13\u001B[0m batch_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     14\u001B[0m res \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mquery(query,\n\u001B[0;32m     15\u001B[0m                  parameters \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrows\u001B[39m\u001B[38;5;124m'\u001B[39m: rows[batch\u001B[38;5;241m*\u001B[39mbatch_size:(batch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m*\u001B[39mbatch_size]\u001B[38;5;241m.\u001B[39mto_dict(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)})\n\u001B[1;32m---> 16\u001B[0m total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mres\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     17\u001B[0m result \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: batch_size,\n\u001B[0;32m     18\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatches_done\u001B[39m\u001B[38;5;124m\"\u001B[39m: batch,\n\u001B[0;32m     19\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m batch_start,\n\u001B[0;32m     20\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: time\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;241m-\u001B[39mstart}\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# print(result)\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "se_boards = [\"ai\", \"cstheory\", \"datascience\", \"softwarerecs\"]\n",
    "add_boards(pd.DataFrame({\"name\": se_boards}), batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conn.query('CREATE INDEX paper_doi_index IF NOT EXISTS FOR (p:Paper) ON (p.doi);')\n",
    "conn.query('CREATE INDEX post_id_index IF NOT EXISTS FOR (p:Post) ON (p.postid);')\n",
    "conn.query('CREATE INDEX comment_id_index IF NOT EXISTS FOR (c:Comment) ON (c.commentid);')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for board in se_boards:\n",
    "    print(\"Board:\", board)\n",
    "    comments_df, posthistory_df = process_stackexchange(board)\n",
    "    posthistory_df = posthistory_df.sort_values('CreationDate').drop_duplicates(subset=[\"PostId\", \"DOIs\"])\n",
    "    add_posts(posthistory_df, batch_size=100)\n",
    "    add_comments(comments_df, batch_size=100)\n",
    "    add_post_links(posthistory_df, batch_size=100)\n",
    "    del(comments_df, posthistory_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3acfef7138f70d2429ae48cbaca4cc964d0577b5663fbd0bd04cb7bf77da6df6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('maat-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}