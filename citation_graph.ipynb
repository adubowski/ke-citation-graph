{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Database wrapper from: https://towardsdatascience.com/create-a-graph-database-in-neo4j-using-python-4172d40f89c4\n",
    "\n",
    "\n",
    "class Neo4jConnection:\n",
    "\n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "\n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "\n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try:\n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session()\n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally:\n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n",
    "port = 7687 # Check if is the case for your server!\n",
    "\n",
    "conn = Neo4jConnection(uri=\"bolt://localhost:\"+str(port),\n",
    "                       user=\"driver\",\n",
    "                       pwd=\"driver\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def insert_data(query, rows, batch_size = 10000):\n",
    "    # Function to handle the updating the Neo4j database in batch mode.\n",
    "\n",
    "    total = 0\n",
    "    batch = 0\n",
    "    start = time.time()\n",
    "    result = None\n",
    "\n",
    "    for batch in tqdm(range(len(rows) // batch_size + 1)):\n",
    "        batch_start = time.time()\n",
    "        res = conn.query(query,\n",
    "                         parameters = {'rows': rows[batch*batch_size:(batch+1)*batch_size].to_dict('records')})\n",
    "        total += res[0]['total']\n",
    "        result = {\"batch_size\": batch_size,\n",
    "                  \"batches_done\": batch,\n",
    "                  \"batch_time\": time.time() - batch_start,\n",
    "                  \"total_time\": time.time()-start}\n",
    "        # print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_papers(rows, batch_size=5000):\n",
    "   # Adds paper nodes and relationships (:Author)-[:AUTHORED]-(:Paper), (:Paper)-[:REFERENCES]-(:Paper)\n",
    "   query = '''\n",
    "    // Create papers\n",
    "    UNWIND $rows as paper\n",
    "    MERGE (p:Paper {paperid: paper.id})\n",
    "    ON CREATE SET\n",
    "    p.title = paper.title,\n",
    "    p.year = paper.year,\n",
    "    p.n_citation = paper.n_citation,\n",
    "    p.doi = paper.doi\n",
    "\n",
    "    // Match authors\n",
    "    WITH paper, p\n",
    "    UNWIND  paper.authors AS author\n",
    "    MERGE (a:Author {authorid: author.id})\n",
    "    ON CREATE SET a.name = author.name\n",
    "    MERGE (a)-[:AUTHORED]->(p)\n",
    "\n",
    "    // Match references\n",
    "    WITH paper, p\n",
    "    UNWIND  paper.references AS refid\n",
    "    MATCH (r:Paper {paperid:refid})\n",
    "    MERGE (p)-[:REFERENCES]->(r)\n",
    "    RETURN count(p:Paper) as total\n",
    "   '''\n",
    "\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Couldn't connect to localhost:7687 (resolved to ('[::1]:7687', '127.0.0.1:7687')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Query failed: Couldn't connect to localhost:7687 (resolved to ('[::1]:7687', '127.0.0.1:7687')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n"
     ]
    }
   ],
   "source": [
    "conn.query('CREATE INDEX paper_id_index IF NOT EXISTS FOR (p:Paper) ON (p.paperid);')\n",
    "conn.query('CREATE INDEX author_id_index IF NOT EXISTS FOR (a:Author) ON (a.authorid);')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:04<?, ?it/s]\u001B[A\n",
      "  0%|          | 0/41 [00:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Couldn't connect to localhost:7687 (resolved to ('[::1]:7687', '127.0.0.1:7687')):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = \"data/dblp_papers_v11.txt\"\n",
    "n_papers = 4107340 # Number of papers in the dataset\n",
    "subset = [\"id\", \"title\", \"year\", \"n_citation\", \"doi\", \"authors\", \"references\"]\n",
    "\n",
    "# TODO: Add tqdm max of the number of papers\n",
    "with open(file, 'r') as f:\n",
    "    for episode in tqdm(range(n_papers // 100000)):\n",
    "        try:\n",
    "            lines = 100000\n",
    "            rows  = []\n",
    "            for line in f:\n",
    "                rows.append(json.loads(line))\n",
    "                lines -= 1\n",
    "                if lines == 0: break\n",
    "            df = pd.DataFrame(rows)\n",
    "            add_papers(df[subset], 1000)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def process_stackexchange(board: str) -> list[pd.DataFrame]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        board (str): Stackexchange board to load. Expected file structure is\n",
    "            ./data/`board`/*.xml\n",
    "\n",
    "    Returns:\n",
    "        list[pd.DataFrame]: List of pandas dataframes with Comments and\n",
    "            PostHistory data with extracted DOIs and markdown links.\n",
    "    \"\"\"\n",
    "    # Regex patterns\n",
    "    DOI_PATTERN = \"10\\.\\d{4,9}/[-._;\\(\\)/:A-Z0-9]+[/A-Z0-9]\"\n",
    "    MD_PATTERN = \"\\[([\\w\\s\\d]+)\\](https?:\\/\\/[\\w\\d./?=#]+)\"\n",
    "\n",
    "    def process_set(set: str) -> pd.DataFrame:\n",
    "        \"\"\"Processes single file in board data\n",
    "\n",
    "        Args:\n",
    "            set (str): One of \"Comments\" or \"PostHistory\"\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Original data with extracted DOIs and Markdown links\n",
    "        \"\"\"\n",
    "        # Load xml file\n",
    "        path = f\"data/{board}/{set}.xml\"\n",
    "        with open(path, encoding=\"utf8\") as file:\n",
    "            df = pd.read_xml(file.read())\n",
    "\n",
    "        # Extract all DOIs using pattern defined before to list per row\n",
    "        df[\"DOIs\"] = df[\"Text\"].apply(lambda text: str(re.findall(DOI_PATTERN, str(text))))\n",
    "        df = df[df[\"DOIs\"] != \"[]\"]\n",
    "        return df\n",
    "\n",
    "    return process_set(\"Comments\"), process_set(\"PostHistory\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_boards(rows, batch_size=5000):\n",
    "    # Adds board nodes\n",
    "    query = '''\n",
    "    UNWIND $rows as board\n",
    "    MERGE (b:Board {boardname: board.name})\n",
    "    RETURN count(b:Board) as total\n",
    "    '''\n",
    "    return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def add_posts(rows, batch_size=5000):\n",
    "   # Adds post nodes\n",
    "   query = '''\n",
    "    // Create posts\n",
    "    UNWIND $rows as post\n",
    "    MERGE (p:Post {postid: post.PostId})\n",
    "    ON CREATE SET\n",
    "    p.text = post.Text,\n",
    "\n",
    "    WITH post, p\n",
    "    UNWIND post.DOIs AS doi\n",
    "    MATCH (r:Paper {doi:doi})\n",
    "    MERGE (p)-[:REFERENCES]->(r)\n",
    "    RETURN count(p:Post) as total\n",
    "   '''\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def add_comments(rows, batch_size=500):\n",
    "   # Adds comment nodes\n",
    "   query = '''\n",
    "    // Create comments\n",
    "    UNWIND $rows as comment\n",
    "    MERGE (c:Comment {commentid: comment.id})\n",
    "    ON CREATE SET\n",
    "    p.title = paper.title\n",
    "\n",
    "    // Match posts\n",
    "    WITH comment, c\n",
    "    MATCH (p:Post {postid: comment.PostId})\n",
    "    MERGE (c)-[:RESPONDS]->(p)\n",
    "\n",
    "    // Match references\n",
    "    WITH comment, c\n",
    "    UNWIND comment.DOIs AS doi\n",
    "    MATCH (r:Paper {doi:doi})\n",
    "    MERGE (c)-[:REFERENCES]->(r)\n",
    "    RETURN count(c:Comment) as total\n",
    "   '''\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def add_post_links(rows, batch_size=5000):\n",
    "   # Adds post nodes\n",
    "   query = '''\n",
    "    // Create posts\n",
    "    UNWIND $rows as post_link\n",
    "    MATCH (p:Post {postid:post_link.postid})\n",
    "    MERGE (c)-[:REFERENCES]->(r)\n",
    "    RETURN count(p:Post) as total\n",
    "   '''\n",
    "   return insert_data(query, rows, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'batch_size': 1,\n 'batches_done': 4,\n 'batch_time': 0.005155801773071289,\n 'total_time': 2.497079610824585}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_boards = [\"ai\", \"cstheory\", \"datascience\", \"softwarerecs\", \"stats\"]\n",
    "add_boards(pd.DataFrame({\"name\": se_boards}), batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for board in se_boards:\n",
    "    comments_df, posthistory_df = process_stackexchange(\"stats\")\n",
    "    posthistory_df = posthistory_df.sort_values('CreationDate').drop_duplicates(subset=[\"PostId\", \"DOIs\"])\n",
    "    add_posts(posthistory_df)\n",
    "    add_comments(comments_df)\n",
    "    # add_post_links(posthistory_df)\n",
    "    del(comments_df, posthistory_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3acfef7138f70d2429ae48cbaca4cc964d0577b5663fbd0bd04cb7bf77da6df6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('maat-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}